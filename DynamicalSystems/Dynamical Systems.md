# Dynamical Systems:

## definition:
A dynamical system (D.S.) is an evolution proccess of the [[State Vector]] $\vec{x}$ according to the [[Evolution Function]] $f$, based on the [[Initial Conditions]] $\vec{x}_0$ .

Dynamical Systems can be 
- discrete: $$\vec{x}_{n+1} = \vec{f}(\vec{x}_n)$$
- continuous:$$\vec{x} = \vec{f}(\vec{x})$$
the evolution of the [[state variables]] of some [[example systems]]:

![[Pasted image 20220805210022.png]]

The evolution of a [[Dynamical System]] is called it's [[Trajectory]].